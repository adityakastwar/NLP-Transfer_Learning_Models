{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNeT- Pytorch-Sentimental-Analysis",
      "provenance": [],
      "mount_file_id": "1EV9yAO4GPvwPP6NT_9gPDmOBN1nVyZ1R",
      "authorship_tag": "ABX9TyO9oKZkvLJORldkNBKse9NR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a65d0fd351da48d3abedbac2d369465d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8fb5329ac514fbdbcb2dd3aee8e8af8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_329a5c01137840f0b2c57ecfbd391303",
              "IPY_MODEL_5697d4ce4a924761b34c304fab4467e7"
            ]
          }
        },
        "e8fb5329ac514fbdbcb2dd3aee8e8af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "329a5c01137840f0b2c57ecfbd391303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cd9f5787c144b0c86d6560fd4d6d14d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2182afc5829c4c729e91d82673c0fa00"
          }
        },
        "5697d4ce4a924761b34c304fab4467e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a75564077413463e8a27c6e3c1e1d729",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:00&lt;00:00, 1.50MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8147b4b71494dd99d28e564b646d8d1"
          }
        },
        "4cd9f5787c144b0c86d6560fd4d6d14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2182afc5829c4c729e91d82673c0fa00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a75564077413463e8a27c6e3c1e1d729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8147b4b71494dd99d28e564b646d8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilkapil/NLP-Transfer_Learning_Models/blob/main/XLNeT_Pytorch_Sentimental_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOEXis_Sx5G"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Dw_kqNngTh"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import torch\n",
        "import re\n",
        "import transformers\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig, XLNetForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsD8WbuK96YO"
      },
      "source": [
        "from tqdm import tqdm, trange \n",
        "import io"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGifLht7JIUG"
      },
      "source": [
        "data = pd.read_csv('/content/tripadvisor_hotel_reviews.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5JM8hMWbz-j",
        "outputId": "65bf50ac-6036-46ff-f8e9-b02788c7a80b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tTsTQ8XHBut"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
        "\n",
        "def clean_text(text):\n",
        "  text = str(text)\n",
        "  for punc in puncts:\n",
        "      if punc in text:\n",
        "          text = text.replace(punc, ' ')\n",
        "  return text\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "    \n",
        "data['Review'] = data['Review'].apply(lambda x: remove_emoji(x)) \n",
        "data['Review'] = data['Review'].apply(lambda x: clean_text(x)) \n",
        "data['Review'] = data['Review'].apply(lambda x: re.sub(r'http\\S+','',x))\n",
        "data['Review'] = data['Review'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "data['Review'] = data['Review'].apply(lambda x:' '.join(x.split()))\n",
        "data['Review'] = data['Review'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF55cvidIDkH"
      },
      "source": [
        "encode = {1:0,\n",
        "          2:1,\n",
        "          3:2,\n",
        "          4:3,\n",
        "          5:4}\n",
        "\n",
        "data['Rating'].replace(encode, inplace=True)         "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-bd8z1PKYu0",
        "outputId": "8b149997-cc93-40ae-f7e9-160425f0f159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data['Rating'].unique()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 2, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ibcA3UiMjNJ"
      },
      "source": [
        "reviews = data['Review']\n",
        "rating = data.Rating.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBmBZ2l-MMFE"
      },
      "source": [
        "#Add [CLS] and [SEP] operator to the end of the sentence\n",
        "\n",
        "reviews = [review + '[SEP] [CLS]' for review in reviews]\n",
        "reviews "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUkC3macJHh4",
        "outputId": "a1c40741-2498-489f-f7a8-37a31c88b7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a65d0fd351da48d3abedbac2d369465d",
            "e8fb5329ac514fbdbcb2dd3aee8e8af8",
            "329a5c01137840f0b2c57ecfbd391303",
            "5697d4ce4a924761b34c304fab4467e7",
            "4cd9f5787c144b0c86d6560fd4d6d14d",
            "2182afc5829c4c729e91d82673c0fa00",
            "a75564077413463e8a27c6e3c1e1d729",
            "a8147b4b71494dd99d28e564b646d8d1"
          ]
        }
      },
      "source": [
        "#tokenize them\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(review) for review in reviews ]\n",
        "# print('Tokenized the first sentence')\n",
        "# print(tokenized_texts[0])\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', padding='post', truncating='post')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a65d0fd351da48d3abedbac2d369465d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snEuNy-PJidS"
      },
      "source": [
        "#Retrieve attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO3v14gKeNk3"
      },
      "source": [
        "#use train test aplit to split the dataset into training and validation dataset\n",
        "\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, rating,\n",
        "                                                                      random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, val_masks, _,_ = train_test_split(attention_masks, input_ids,\n",
        "                                               test_size=0.1, random_state=2018)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Q-NQAFjZUf"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA-ncBcXjb6U"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_labels, train_masks)\n",
        "val_data = TensorDataset(val_inputs, val_labels, val_masks)\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              sampler=RandomSampler(train_data),\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "val_dataloader = DataLoader(val_data,\n",
        "                            sampler=SequentialSampler(val_data),\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADUKUJ9c4C1O",
        "outputId": "6d9d0da4-26e2-4276-a633-97478780f3e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data['Rating'].unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 2, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB4F8A4c3oBE"
      },
      "source": [
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = len(data['Rating'].unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQyIMWii3uXR"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7H052ag5pnU"
      },
      "source": [
        "param_optimizer =  list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_9rwouO5Qhl"
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr = 3e-5, eps=1e-10)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEzq7x79lkf"
      },
      "source": [
        "#define a acccuracy function\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz_CHxX59mJ9"
      },
      "source": [
        "train_loss_set = []\n",
        "epochs = 4\n",
        "for _ in trange(epochs, desc='Epochs'):\n",
        "  model.train()\n",
        "\n",
        "  #tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0,0\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_inputs = batch[0]\n",
        "    b_labels = batch[1]\n",
        "    b_attention_mask = batch[2]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(b_inputs, \n",
        "                    attention_mask = b_attention_mask, \n",
        "                    token_type_ids=None, \n",
        "                    labels = b_labels)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "    logits = outputs[1]\n",
        "    train_loss_set.append(loss.item())\n",
        "    #Backward pass\n",
        "    loss.backward()\n",
        "    #Update parameters and take a step using the computed gradient \n",
        "    optimizer.step()\n",
        "\n",
        "    #Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_inputs.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print('Training Loss : {}'.format(tr_loss/nb_tr_steps))\n",
        "\n",
        "#VALIDATION\n",
        "\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps , nb_eval_examples = 0,0\n",
        "\n",
        "for batch in val_dataloader:\n",
        "  model.eval()\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_inputs = batch[0]\n",
        "  b_labels = batch[1]\n",
        "  b_attention_mask = batch[2]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_inputs, b_attention_mask, token_type_ids=None)\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, labels)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vejao48bFsjv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}